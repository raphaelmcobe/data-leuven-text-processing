<!DOCTYPE html>
<html lang="en">
<head>
  <meta name="generator" content="HTML Tidy for HTML5 for Apple macOS version 5.6.0">
  <meta charset="utf-8">
  <title>Processing Textual Data</title>
  <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
  <meta name="author" content="Raphael Cobe">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" href="dist/reset.css">
  <link rel="stylesheet" href="dist/reveal.css">
  <link rel="stylesheet" href="dist/style.css">
  <link rel="stylesheet" href="dist/theme/night.css" id="theme"><!-- Theme used for syntax highlighting of code -->
  <link rel="stylesheet" href="plugin/highlight/monokai.css" id="highlight-theme">
</head>
<body>
  <div class="reveal">
    <!-- Any section element inside of this container is displayed as a slide -->
    <div class="slides">
      <section>
        <a href="https://www.datascienceschools.org/" target="_blank"><div style="height: 120px; margin: 0 auto 10rem auto; background: transparent;"><img src="img/DS_logo_CDT-RDA-mono-inverse.png"></img></div></a>
      <!--<a href="https://revealjs.com"><img src="https://static.slid.es/reveal/logo-v1/reveal-white-text.svg" alt="reveal.js logo" style="height: 180px; margin: 0 auto 4rem auto; background: transparent;" class="demo-logo"></a>-->
        <h3>Processing Textual Data with Python</h3>
	<p><small><em><a href="http://twitter.com/raphaelmcobe">@raphaelmcobe</a></em></small></p>
      </section>

      <section data-markdown data-separator="^---" 
               data-separator-vertical="^--"
               data-separator-notes="^\nNote:"
               data-charset="iso-8859-15"
               style="text-align: left;">
        <textarea data-template>
          ## Introduction/Motivation
          <!-- .slide: data-background="#6d8ba7" -->

          --

          ### A (few) word (s) on unstructure data
          - Structured or Semistructured data includes fields or markup that
          enable it to be <span class="highlight">easily parsed by a
          computer</span>;
          - Language is <span class="highlight">unstructured data</span> that
          has been <span class="highlight">produced by people</span> to
          be <span class="highlight">understood by other people</span>;
          - Retrieving information from unstructured data <span
            class="highlight">is essential</span>!  - It is estimated that [80%
          of the world’s data is
          unstructured](https://www.ibm.com/blogs/watson/2016/05/biggest-data-challenges-might-not-even-know/).
          - Unstructured data <span class="fragment highlight-red">*is not
            random!*</span>
            - Linguistic properties that make it very understandable to other
            people <!-- .element: class="fragment" -->

          --

          ### Language as Data
          - Text mining:
            - Process of deriving insights from (unstructured) text data;
          - Natural Language Processing (NLP): 
            - Part of computer science and artificial intelligence which deals
            with human languages.  - Sentiment Analysis:
            - Just a small variant of Text mining;

          Note:
          This is a simple note
          - Test 
          - Test2

          --

          ### Understanding text is hard
          - Real-world data is often <span class="highlight-r">messy</span> and <span class="highlight-r">noisy</span>;
          - Several factors that makes this process hard:
            - Encoding scheme used (ASCII, UTF-8, UTF-16, Latin-1, etc.); <!-- .element: class="fragment" -->
            - hundreds of natural languages, each of which has different syntax
            rules; <!-- .element: class="fragment" -->
            - Words can be ambiguous (dependent on their context);<!-- .element: class="fragment" -->
            - case-sensitive, punctuation, numbers, hyperlinks, the use of
            emoticons and emojis <!-- .element: class="fragment" --> <span>&#x1F61C;</span><!-- .element: class="fragment" -->
            - synonyms, abbreviation, acronyms, and spelling errors;<!-- .element: class="fragment" -->
          - often need to understand which words in a sentence are nouns and
          which are verbs; <!-- .element: class="fragment" -->

          ---

          ## Processing Textual data
          <!-- .slide: data-background="#6d8ba7" -->

          --

          ### How to process textual data?
          - “the numbers don’t lie” and not “the text doesn’t lie”;
          - Machine learning: 
            - train statistical models on language as it changes;
          - building models of language on <span class="highlight">
            context-specific corpora</span>;
          - Model that describes language and can make inferences based on that
          description
          - To take advantage of the predictability of text, we need to define
          a constrained, numeric decision space on which the model can compute;

          --

          ### How to process textual data?
          - Break the text processing into steps:
            - <span class="fragment highlight-blue">Finding Parts of Text</span>
            - Finding Sentences
            - Finding People and Things
            - Detecting Parts of Speech
            - <span class="fragment highlight-blue">Classifying Text and
              Documents</span>
            - Extracting Relationships
            - Combined Approaches 
          
          ---
          <!-- .slide: data-background="#6d8ba7" -->
          ## Finding Parts of Text

          Examples taken from [Real Python Regular Expressions
          Tutorial](https://realpython.com/regex-python/)
          --

          ### Regular Expressions
          A (very) brief history
          - In 1951, mathematician Stephen Cole Kleene described the concept of
          a regular language, a language that is recognizable by a finite
          automaton;
          -  In the mid-1960s, computer science pioneer Ken Thompson, one of
          the original designers of Unix, implemented pattern matching in the
          QED text editor;
          - Appeared in many programming languages, editors, and other tools as
          a means of determining whether a string matches a specified pattern;

          --
        
          ### The Python `re` module
          - Regex functionality in Python resides in a module named `re`. The
          `re` module contains many useful functions and methods. Let's play a
          little bit with the `search()` function:
          - `re.search(<regex>, <string>)`

          ```python[1|2|3-4]
          >>> import re
          >>> text = "foo123foo"
          >>> re.search("123", text)
          <re.Match object; span=(3, 6), match='123'>
          ```

          --
        
          ### The Python `re` module
          - `span=(3, 6)` indicates the portion of `<string>` in which the
          match was found. This means the same thing as it would in slice
          notation:

          ```python[1|2]
          >>> text[3:6]
          '123'
          ```

          --

          ### Regular Expressions in Python
          - Any character or sequence of carachters is a valid regular
          expression;
          - The `search()` function returns the first sequence of characters
          that matches the RE;

          ```python[2-3|4-5]
          >>> text="abc123abc"
          >>> re.search("a", text)
          <re.Match object; span=(0, 1), match='a'>
          >>> re.search("abc", text)
          <re.Match object; span=(0, 3), match='abc'>
          ```

          --

          ### Regular Expressions in Python
          Metacharacters
          - Real power of regex matching in Python emerges when `<regex>`
          contains special characters called <span class="highlight">metacharacters</span>;
          - Unique meaning to the regex matching engine;
          - **Character class**:
            - Matches any single character that is in the class;
            - Defined using square brackets ([]);
            - Can be used to specify intervals
          ```python[1-2|3-4|5-6|7-8]
          >>> re.search('[0-9]', "abc123abc")
          <re.Match object; span=(3, 4), match='1'>
          >>> re.search('[2-9]', "abc123abc")
          <re.Match object; span=(4, 5), match='2'>
          >>> re.search('[0-9][0-9][0-9]', "abc123abc")
          <re.Match object; span=(3, 6), match='123'>
          >>> re.search('[2-9][0-9]', "abc123abc")
          <re.Match object; span=(4, 6), match='23'>
          ```

          --

          ### Regular Expressions in Python
          Metacharacters - character classes
          - Can have all the characters enumerated:
          ```python[1-2|3-4]
          >>> re.search('ab[cde]', "abc123abc")
          <re.Match object; span=(0, 3), match='abc'>
          >>> re.search('ab[cde]', "abd123abc")
          <re.Match object; span=(0, 3), match='abd'>
          ```
          - Complement a character class by specifying `^` as the first
          character:
          ```python
          >>> re.search('ab[^cde]', "abc abd abe abf")
          <re.Match object; span=(12, 15), match='abf'>
          ```

          --

          ### Regular Expressions in Python
          Metacharacters
          -  The dot (.) metacharacter matches any character except a newline,
          so it functions like a wildcard:

          ```python[1-2|3-4]
          >>> re.search('1.3', "abc123abc")
          <re.Match object; span=(3, 6), match='123'>
          >>> print(re.search('foo.bar', 'foobar'))
          None
          ```

          --

          ### Regular Expressions in Python
          Metacharacters
          - Quantifiers:
            - Indicates how many times that portion must occur for the match to succeed
            - `*` matches zero or more repetitions of the preceding regex:
            ```python[1-2|3-4|5-6]
            >>> re.search('foo-*bar', 'foobar')  # Zero dashes
            <re.Match object; span=(0, 6), match='foobar'>
            >>> re.search('foo-*bar', 'foo-bar') # One dash
            <re.Match object; span=(0, 7), match='foo-bar'>
            >>> re.search('foo-*bar', 'foo--bar') # Two dashes
            <re.Match object; span=(0, 8), match='foo--bar'>
            ```
            - `.*` This matches zero or more occurrences of any character:
            ```python
            >>> re.search('foo.*bar', '# foo $qux@grault % bar #')
            <re.Match object; span=(2, 23), match='foo $qux@grault % bar'>
            ```

          --

          ### Regular Expressions in Python
          Metacharacters
          - Quantifiers:
            - `+` matches one or more repetitions of the preceding regex;
            - `?` matches zero or one repetitions of the preceding regex;
            - `{m}` matches exactly `m` repetitions of the preceding regex;
            - `{m,n}` matches any number of repetitions of the preceding regex
            from `m` to `n`, inclusive.

          --

          ### Regular Expressions in Python
          Metacharacters
          - Anchors: zero-width matches. 
            - Don’t match any actual characters in the search string;
            - Dictates a particular location in the search string where a match
            must occur;
            - `^` or `\A` anchor a match to the start of the text:
            ```python[1-2|3-4]
            >>> re.search('^foo', 'foobar')
            <re.Match object; span=(0, 3), match='foo'>
            >>> re.search('^foo', 'barfoo')
            None
            ```
            - `$` or `\Z` anchor a match to the end of the text:
            ```python[1-2|3-4]
            >>> re.search('bar$', 'foobar')
            <re.Match object; span=(3, 6), match='bar'>
            >>> re.search('bar$', 'barfoo')
            None
            ```
          
          --

          ### Regular Expressions
          Why are they so important?
          
          - Removing uninportant text:
            - Use the `re.sub()` function;
            - Strip all non alphanumerical characters:
          ```python
          >>> re.sub('[^a-zA-Z0-9_]+', '', "foo1!bar#~2")
          'foo1bar2'
          ```
            - Remove all punctuation signs (`\s` represents any whitespace
            character):
          ```python
          >>> re.sub("[^a-zA-Z0-9_]\s",' ',"Foo. Bar? Foo.Bar")
          'Foo Bar Foo.Bar'
          ```
            - Remove all numbers from the text:
          ```python
          >>> re.sub('[0-9]+', '', "Foo 123 Bar 456")
          'Foo  Bar '
          ```

          ---
          ## Further Cleaning the Text
          <!-- .slide: data-background="#6d8ba7" -->
          Standard text mining procedures to extract useful features from the
          news contents, including:
          <ul>
            <li><b>tokenization</b>,</li>
            <li><b>removing stopwords</b>, and </li>
            <li><b>lemmatization/stemming</b></li>
          </ul>

          --

          ### Tokenization
          - The process of breaking strings into tokens which in turn are small
          structures or units;
          - Taking individual words rather than sentences breaks down the
          connections between words
          - It is efficient and convenient for computers to analyze
          - Most of the times, discovering what words appear in a text and
          counting the times that these words appear is sufficient to give
          insightful results;
          - Transforms a text into a list of words;
          - Remove useless information (using Regular Expressions!)

          --

          ### Python [Natural Language Toolkit - NLTK](https://www.nltk.org/)
          - Leading platform for building Python programs to work with human
          language data
          - A wonderful tool for teaching, and working in, computational
          linguistics using Python;
          - Free reference [book](http://www.nltk.org/book/)
          - Open Source;
          ```python
          >>> import nltk
          >>> nltk.download()
          ```

          --

          ### Python [Natural Language Toolkit - NLTK](https://www.nltk.org/)
          Tokenization
          ```python[1-2|4-8|10-11]
          # importing word_tokenize from nltk
          from nltk.tokenize import word_tokenize
          
          text = """
          Ground control to Major Tom (10, 9, 8, 7).
          Commencing countdown, engines on (6, 5, 4, 3).
          Check ignition, and may God's love be with you (2, 1, lift off).
          """

          token = word_tokenize(text)
          print(token)

          ```
          ```
          ['Ground', 'control', 'to', 'Major', 'Tom', '(', '10', ',', '9', ',', '8', ',', '7', ')', '.', 'Commencing', 'countdown', ',', 'engines', 'on', '(', '6', ',', '5', ',', '4', ',', '3', ')', '.', 'Check', 'ignition', ',', 'and', 'may', 'God', "'s", 'love', 'be', 'with', 'you', '(', '2', ',', '1', ',', 'lift', 'off', ')', '.']
          ```

          --

          ### Python [Natural Language Toolkit - NLTK](https://www.nltk.org/)
          Cleaning Before Tokenization
          ```python[1-2|4-5|7-8|10-12|14-16]
          # Remove non alphanumeric character 
          text = re.sub("[^a-zA-Z0-9]",' ',text)

          # Remove all numbers
          text = re.sub('[0-9]+', '', text)

          # Remove extra whitespaces
          text = re.sub('\s+', ' ', text)

          # Remove beginning and trailing whitespaces
          text = re.sub('^\s', '', text)
          text = re.sub('\s$', '', text)
          ```


          --

          ### Python [Natural Language Toolkit - NLTK](https://www.nltk.org/)
          Tokenization
          ```python
          # Now tokenize
          token = word_tokenize(text)
          print(token)
          ```
          ```
          ['Ground', 'control', 'to', 'Major', 'Tom', 'Commencing', 'countdown', 'engines', 'on', 'Check', 'ignition', 'and', 'may', 'God', 's', 'love', 'be', 'with', 'you', 'lift', 'off']
          ```
          - Finding the frequency distinct in the tokens
          ```python[1|3-4]
          from nltk.probability import FreqDist
          fdist = FreqDist(token)
          fdist
          ```

          ```
          FreqDist({'Ground': 1, 'control': 1, 'to': 1, 'Major': 1, 'Tom': 1, 'Commencing': 1, 'countdown': 1, 'engines': 1, 'on': 1, 'Check': 1, ...})
          ```

          --

          ### Python [Natural Language Toolkit - NLTK](https://www.nltk.org/)
          Tokenization
          - Let's check all of the lyrics at once:

          ```python
          # load data and concatenate all lyrics
          data = pd.read_csv("./bowie_songs.csv")
          bowie_lyrics = " ".join(data.iloc[:,1])

          # tokenize
          token = word_tokenize(bowie_lyrics)

          # build the frequency distribution and print the top 10 occurences:
          fdist = FreqDist(token)
          fdist.most_common(10)
          ```
          ```
[(',', 2916), ('the', 2386), ('I', 2344), ('you', 1313), ('a', 1140), ('to', 993), ("'s", 870), ('and', 812), ('of', 778), ('me', 762)]

          ```
        </textarea>
      </section>


      <section data-auto-animate="">
        <h2 data-id="code-title">Pretty Code</h2>
        <pre data-id="code-animation"><code class="hljs" data-trim="" data-line-numbers="">
                                                import React, { useState } from 'react';

                                                function Example() {
                                                  const [count, setCount] = useState(0);

                                                  return (
                                                    ...
                                                  );
                                                }
                                        </code></pre>
        <p>Code syntax highlighting courtesy of <a href="https://highlightjs.org/usage/">highlight.js</a>.</p>
      </section>
      <section data-auto-animate="">
        <h2 data-id="code-title">With animations</h2>
        <pre data-id="code-animation"><code class="hljs" data-trim="" data-line-numbers="|4,8-11|17|22-24">
<script type="text/template">

                                                import React, { useState } from 'react';

                                                function Example() {
                                                  const [count, setCount] = useState(0);

                                                  return (
                                                    <div>
                                                      <p>You clicked {count} times</p>
                                                      <button onClick={() => setCount(count + 1)}>
                                                        Click me
                                                      </button>
                                                    </div>
                                                  );
                                                }

                                                function SecondExample() {
                                                  const [count, setCount] = useState(0);

                                                  return (
                                                    <div>
                                                      <p>You clicked {count} times</p>
                                                      <button onClick={() => setCount(count + 1)}>
                                                        Click me
                                                      </button>
                                                    </div>
                                                  );
                                                }
</script></code></pre>
      </section>
    </div>
  </div>
  <script src="dist/reveal.js"></script> 
  <script src="plugin/zoom/zoom.js"></script> 
  <script src="plugin/notes/notes.js"></script> 
  <script src="plugin/search/search.js"></script> 
  <script src="plugin/markdown/markdown.js"></script> 
  <script src="plugin/highlight/highlight.js"></script> 
  <script>


                        // Also available as an ES module, see:
                        // https://revealjs.com/initialization/
                        Reveal.initialize({
                                controls: true,
                                progress: true,
                                center: true,
                                hash: true,
                                width: 1280,
                                height: 720,
                                // Learn about plugins: https://revealjs.com/plugins/
                                plugins: [ RevealZoom, RevealNotes, RevealSearch, RevealMarkdown, RevealHighlight ]
                        });

  </script>
</body>
</html>
